# week2_triton_verify.py
import torch
import torch.nn.functional as F
from fla.ops.gated_delta_rule import chunk_gated_delta_rule

def naive_titans_recurrence(q, k, v, beta, g):
    """
    ç”¨æœ€ç®€å•çš„ Python å¾ªç¯æ‰‹å†™ Titans (Delta Rule) å…¬å¼ã€‚
    å…¬å¼: S_t = g_t * S_{t-1} + beta_t * (v_t - S_{t-1} @ k_t) @ k_t.T
    """
    batch_size, seq_len, num_heads, head_dim = q.shape
    d_head = head_dim
    
    # åˆå§‹åŒ–çŠ¶æ€ S (Batch, Heads, Dim, Dim)
    state = torch.zeros(batch_size, num_heads, d_head, d_head, device=q.device, dtype=torch.float32)
    outputs = []

    for t in range(seq_len):
        k_t = k[:, t].float() # (B, H, D)
        v_t = v[:, t].float()
        beta_t = beta[:, t].float()
        g_t = g[:, t].float() if g is not None else 1.0
        
        # --- Titans çš„çµé­‚ï¼šè¯¯å·®è®¡ç®— ---
        # 1. é¢„æµ‹/é‡æ„ (Recall): çœ‹çœ‹å½“å‰è®°å¿† S èƒ½ä¸èƒ½é¢„æµ‹å‡º v
        # S: (B, H, D, D), k_t: (B, H, D, 1) -> v_pred: (B, H, D, 1)
        v_pred = torch.einsum('bhmn, bhnk -> bhmk', state, k_t[..., None]).squeeze(-1)
        
        # 2. è®¡ç®—æƒŠå¥‡åº¦ (Surprise/Error): å®é™…å€¼ - é¢„æµ‹å€¼
        error = v_t - v_pred
        
        # 3. æ›´æ–°è®°å¿† (Update): ç”¨è¯¯å·®å»ä¿®æ­£è®°å¿†
        # delta = beta * error * k^T
        delta = torch.einsum('bhm, bhn -> bhmn', error * beta_t[..., None], k_t)
        
        # åº”ç”¨é—å¿˜é—¨ g_t å¹¶æ›´æ–°
        if g is not None:
            state = state * g_t[..., None, None]
        state = state + delta
        
        # 4. è®¡ç®—å½“å‰æ­¥çš„è¾“å‡º (Output): q * S
        o_t = torch.einsum('bhmn, bhnk -> bhmk', state, q[:, t].float()[..., None]).squeeze(-1)
        outputs.append(o_t)

    return torch.stack(outputs, dim=1)

def run_week2_verification():
    print("ğŸ”¬ å¼€å§‹ Week 2 éªŒè¯ï¼šTitans (Gated DeltaNet) ç®—å­æ·±åº¦æ¢ç©¶")
    device = "cuda"
    dtype = torch.bfloat16
    
    # --------------------------
    # 1. æ•°å­¦ä¸€è‡´æ€§éªŒè¯
    # --------------------------
    print("\n[å®éªŒ 1] æ•°å­¦å…¬å¼å¯¹é½æµ‹è¯• (Triton vs Naive Python)")
    B, L, H, D = 2, 64, 4, 32
    torch.manual_seed(42)
    
    # éšæœºç”Ÿæˆæ•°æ®
    q = torch.randn(B, L, H, D, device=device, dtype=dtype)
    k = torch.randn(B, L, H, D, device=device, dtype=dtype)
    v = torch.randn(B, L, H, D, device=device, dtype=dtype)
    beta = torch.rand(B, L, H, device=device, dtype=dtype)
    g = torch.rand(B, L, H, device=device, dtype=dtype) # é—å¿˜é—¨

    # A. è¿è¡Œ Triton ç®—å­ (MoM é¡¹ç›®é‡Œç”¨çš„)
    # æ³¨æ„ï¼šæˆ‘ä»¬è¿™é‡Œå…³é—­ l2norm ä»¥ä¾¿å’Œç®€å•å…¬å¼å¯¹é½ï¼Œä¸”é˜²æ­¢ä¹‹å‰é‡åˆ°çš„ OOM
    o_triton, _ = chunk_gated_delta_rule(q, k, v, g, beta, 
                                         use_qk_l2norm_in_kernel=False, 
                                         output_final_state=False)

    # B. è¿è¡Œæ‰‹å†™ Naive Titans
    o_naive = naive_titans_recurrence(q, k, v, beta, g).to(dtype)

    # C. æ¯”è¾ƒå·®å¼‚
    diff = (o_triton - o_naive).abs().max().item()
    print(f"   >>> æœ€å¤§è¯¯å·®: {diff:.6f}")
    
    if diff < 1e-2:
        print("   âœ… éªŒè¯é€šè¿‡ï¼šåº•å±‚ Triton ç®—å­å®Œç¾æ‰§è¡Œäº† Titans çš„è¯¯å·®æ›´æ–°å…¬å¼ã€‚")
    else:
        print("   âŒ éªŒè¯å¤±è´¥ï¼šç®—å­è¡Œä¸ºä¸å…¬å¼ä¸ä¸€è‡´ï¼Œéœ€æ£€æŸ¥ã€‚")

    # --------------------------
    # 2. æƒŠå¥‡åº¦æœºåˆ¶éªŒè¯ (The "Surprise" Test)
    # --------------------------
    print("\n[å®éªŒ 2] æƒŠå¥‡åº¦æœºåˆ¶éªŒè¯ (The Surprise Test)")
    print("   ç›®æ ‡ï¼šéªŒè¯å½“è¾“å…¥é‡å¤ä¿¡æ¯æ—¶ï¼ŒTitans æ˜¯å¦ä¼šè‡ªåŠ¨åœæ­¢æ›´æ–°ï¼ˆå› ä¸ºè¯¯å·®ä¸º0ï¼‰ã€‚")
    
    # æ„é€ ä¸€ä¸ªç‰¹æ®Šçš„åºåˆ—ï¼šç¬¬0æ­¥å’Œç¬¬1æ­¥è¾“å…¥å®Œå…¨ä¸€æ ·çš„ k, v
    # å‡è®¾ k æ˜¯å½’ä¸€åŒ–çš„ï¼Œbeta=1 (å…¨é‡æ›´æ–°)
    L_toy = 2
    k_toy = torch.randn(1, L_toy, 1, 16, device=device, dtype=dtype)
    k_toy = F.normalize(k_toy, dim=-1) # å½’ä¸€åŒ–å¾ˆé‡è¦
    k_toy[:, 1] = k_toy[:, 0]          # ç¬¬äºŒæ­¥å®Œå…¨é‡å¤ç¬¬ä¸€æ­¥
    
    v_toy = torch.randn(1, L_toy, 1, 16, device=device, dtype=dtype)
    v_toy[:, 1] = v_toy[:, 0]          # Value ä¹Ÿé‡å¤
    
    beta_toy = torch.ones(1, L_toy, 1, device=device, dtype=dtype) # å­¦ä¹ ç‡=1
    g_toy = torch.ones(1, L_toy, 1, device=device, dtype=dtype)    # ä¸é—å¿˜
    q_toy = torch.randn(1, L_toy, 1, 16, device=device, dtype=dtype)

    # è¿è¡Œæ‰‹å†™ Titans å¼•æ“æ¥è§‚å¯Ÿå†…éƒ¨ State å˜åŒ–
    # æˆ‘ä»¬ç¨å¾®æ”¹ä¸€ä¸‹ naive å‡½æ•°æ¥è¿”å›çŠ¶æ€å¢é‡
    print("   ... æ­£åœ¨æ¨¡æ‹Ÿè¾“å…¥åºåˆ—: [Token A, Token A]")
    
    # --- Step 0 ---
    state = torch.zeros(1, 1, 16, 16, device=device, dtype=torch.float32)
    k0, v0 = k_toy[:, 0].float(), v_toy[:, 0].float()
    
    # é¢„æµ‹
    pred0 = state @ k0[..., None]
    # è¯¯å·®
    err0 = v0[..., None] - pred0
    # æ›´æ–°é‡
    delta0 = err0 @ k0[..., None].transpose(-1, -2)
    state = state + delta0
    print(f"   [Step 0] åˆå§‹çŠ¶æ€ä¸ºç©ºï¼Œè¯¯å·®èŒƒæ•°: {err0.norm().item():.4f} -> äº§ç”Ÿæ›´æ–°é‡: {delta0.norm().item():.4f}")

    # --- Step 1 (é‡å¤è¾“å…¥) ---
    k1, v1 = k_toy[:, 1].float(), v_toy[:, 1].float() # k1 == k0, v1 == v0
    
    # é¢„æµ‹ (æ­¤æ—¶ State å·²ç»è®°ä½äº† k0->v0)
    pred1 = state @ k1[..., None]
    # è¯¯å·® (ç†è®ºä¸Šåº”è¯¥æ¥è¿‘0)
    err1 = v1[..., None] - pred1
    # æ›´æ–°é‡
    delta1 = err1 @ k1[..., None].transpose(-1, -2)
    
    print(f"   [Step 1] è¾“å…¥é‡å¤æ•°æ®ï¼Œè¯¯å·®èŒƒæ•°: {err1.norm().item():.4f} -> äº§ç”Ÿæ›´æ–°é‡: {delta1.norm().item():.4f}")
    
    # éªŒè¯é€»è¾‘
    ratio = delta1.norm() / (delta0.norm() + 1e-6)
    print(f"   >>> æ›´æ–°é‡ç¼©å‡æ¯”ç‡ (Step1 / Step0): {ratio.item():.4%}")
    
    if ratio < 0.1:
        print("   âœ… éªŒè¯é€šè¿‡ï¼šæ¨¡å‹è¡¨ç°å‡ºå¼ºçƒˆçš„â€œæµ‹è¯•æ—¶è®­ç»ƒâ€ç‰¹æ€§ï¼")
        print("      å› ä¸ºå·²ç»è®°ä½äº†è¯¥ä¿¡æ¯ï¼Œç¬¬äºŒæ¬¡é‡åˆ°æ—¶æƒŠå¥‡åº¦ä¸º0ï¼Œå‡ ä¹ä¸æ¶ˆè€—è®°å¿†å®¹é‡ã€‚")
    else:
        print("   âŒ éªŒè¯å¤±è´¥ï¼šæ¨¡å‹ä»åœ¨é‡å¤è®°å¿†ï¼Œè¿™é€€åŒ–æˆäº†æ™®é€šçš„ Linear Attentionã€‚")

if __name__ == "__main__":
    run_week2_verification()